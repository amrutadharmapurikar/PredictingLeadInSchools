{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_is_valid(feature_row):\n",
    "    if feature_row['min_lead_quantity'] == -1:\n",
    "        return False\n",
    "    if feature_row['lat'] == 'unknown' or feature_row['lat'] == -1:\n",
    "        return False\n",
    "    if feature_row['long'] == 'unknown' or feature_row['long'] == -1:\n",
    "        return False\n",
    "    if feature_row['tract'] == 'unknown' or feature_row['tract'] == -1:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_map = pickle.load(open(\"/Users/23amrutad/Projects/LeadProj/ProjectData/final_data.pkl\", 'rb'))\n",
    "all_features = []\n",
    "labels = []\n",
    "for k, v in name_map.items():\n",
    "    if row_is_valid(v):\n",
    "        features = []\n",
    "        if v['min_lead_quantity'] >= 5.0:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "        for f in v.keys():\n",
    "            if f != 'addr' and f != 'min_lead_quantity':\n",
    "                features.append(v[f])\n",
    "                if type(v[f]) == type(''):\n",
    "                    print(v[f])\n",
    "        all_features.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(all_features)\n",
    "y = np.array(labels)\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-conservative",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-enlargement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-battlefield",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-contact",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-simon",
   "metadata": {},
   "source": [
    "# Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"uniform\")\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy_clf.predict(X_test)\n",
    "f1_dummy = f1_score(y_test, y_pred_dummy)\n",
    "print(\"f1: \", f1_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f120e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC curve\n",
    "metrics.plot_roc_curve(dummy_clf, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "class_names = ['lead', 'not_lead']\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        dummy_clf,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-saying",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-cancer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "actual-donna",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=None, random_state=1, n_estimators = 15)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"f1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC curve\n",
    "metrics.plot_roc_curve(clf, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-aviation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "class_names = ['not_lead', 'lead']\n",
    "precision = 0\n",
    "recall = 0\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        clf,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "    precision = disp.confusion_matrix[0]\n",
    "    recall = disp.confusion_matrix[1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = precision[0]\n",
    "FP = precision[1]\n",
    "FN = recall[0]\n",
    "TN = recall[1]\n",
    "print(TP, FP, FN, TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "print(precision, recall)\n",
    "f1_ = 2*precision*recall/(precision+recall)\n",
    "print(f1_, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-killing",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"f1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC curve\n",
    "metrics.plot_roc_curve(clf, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "class_names = ['not_lead', 'lead']\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator (\n",
    "        clf,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
